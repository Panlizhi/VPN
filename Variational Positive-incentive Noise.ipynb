{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2e56a-214c-4d36-8a4b-8121080730db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复现VPN在CIFAR10数据集上\n",
    "# 数据及说明 https://blog.csdn.net/DaVinciL/article/details/78793067\n",
    "# Variational Positive-incentive Noise: How Noise Benefits Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be32eefb-80c5-4287-bb57-e0b71a72f03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Training data shape: (50000, 32, 32, 3)\n",
      "Test data shape: (10000, 32, 32, 3)\n",
      "Using device: cuda\n",
      "Epoch 1/100, Batch 0/196, Loss: 2.4464, Base Loss: 2.4452, VPN Loss: 2.4491\n",
      "Epoch 1/100, Batch 50/196, Loss: 1.8232, Base Loss: 1.7518, VPN Loss: 1.9899\n",
      "Epoch 1/100, Batch 100/196, Loss: 1.6892, Base Loss: 1.6264, VPN Loss: 1.8358\n",
      "Epoch 1/100, Batch 150/196, Loss: 1.6439, Base Loss: 1.5855, VPN Loss: 1.7803\n",
      "Visualization saved for epoch 0 at: visualizations/epoch_0\n",
      "Epoch 1/100 - Total Loss: 2.3457, Acc: 0.3165\n",
      "Epoch 2/100, Batch 0/196, Loss: 1.5784, Base Loss: 1.5239, VPN Loss: 1.7058\n",
      "Epoch 2/100, Batch 50/196, Loss: 1.3313, Base Loss: 1.2584, VPN Loss: 1.5012\n",
      "Epoch 2/100, Batch 100/196, Loss: 1.3743, Base Loss: 1.2528, VPN Loss: 1.6578\n",
      "Epoch 2/100, Batch 150/196, Loss: 1.3447, Base Loss: 1.2445, VPN Loss: 1.5785\n",
      "Epoch 2/100 - Total Loss: 1.3472, Acc: 0.4487\n",
      "Epoch 3/100, Batch 0/196, Loss: 1.0485, Base Loss: 0.9291, VPN Loss: 1.3269\n",
      "Epoch 3/100, Batch 50/196, Loss: 1.1292, Base Loss: 1.0072, VPN Loss: 1.4137\n",
      "Epoch 3/100, Batch 100/196, Loss: 1.0503, Base Loss: 0.9702, VPN Loss: 1.2374\n",
      "Epoch 3/100, Batch 150/196, Loss: 1.0543, Base Loss: 0.9602, VPN Loss: 1.2741\n",
      "Epoch 3/100 - Total Loss: 1.1217, Acc: 0.5120\n",
      "Epoch 4/100, Batch 0/196, Loss: 1.0294, Base Loss: 0.9175, VPN Loss: 1.2904\n",
      "Epoch 4/100, Batch 50/196, Loss: 1.0001, Base Loss: 0.8856, VPN Loss: 1.2674\n",
      "Epoch 4/100, Batch 100/196, Loss: 1.0152, Base Loss: 0.8880, VPN Loss: 1.3120\n",
      "Epoch 4/100, Batch 150/196, Loss: 1.0881, Base Loss: 0.9718, VPN Loss: 1.3595\n",
      "Epoch 4/100 - Total Loss: 1.0109, Acc: 0.5409\n",
      "Epoch 5/100, Batch 0/196, Loss: 0.8824, Base Loss: 0.7350, VPN Loss: 1.2264\n",
      "Epoch 5/100, Batch 50/196, Loss: 0.8994, Base Loss: 0.7702, VPN Loss: 1.2010\n",
      "Epoch 5/100, Batch 100/196, Loss: 0.8761, Base Loss: 0.7491, VPN Loss: 1.1727\n",
      "Epoch 5/100, Batch 150/196, Loss: 0.8610, Base Loss: 0.7242, VPN Loss: 1.1803\n",
      "Epoch 5/100 - Total Loss: 0.9192, Acc: 0.5692\n",
      "Epoch 6/100, Batch 0/196, Loss: 1.0114, Base Loss: 0.8509, VPN Loss: 1.3859\n",
      "Epoch 6/100, Batch 50/196, Loss: 0.8841, Base Loss: 0.7435, VPN Loss: 1.2122\n",
      "Epoch 6/100, Batch 100/196, Loss: 0.8875, Base Loss: 0.7712, VPN Loss: 1.1587\n",
      "Epoch 6/100, Batch 150/196, Loss: 0.9721, Base Loss: 0.8424, VPN Loss: 1.2745\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 565\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;66;03m# 可视化噪声（每5个epoch）\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sample_originals) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 565\u001b[0m     \u001b[43mvisualize_directly\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_originals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_noises\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_noise_maps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_noisy_imgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m total_samples\n\u001b[1;32m    576\u001b[0m epoch_acc \u001b[38;5;241m=\u001b[39m correct_predictions \u001b[38;5;241m/\u001b[39m total_samples\n",
      "Cell \u001b[0;32mIn[11], line 243\u001b[0m, in \u001b[0;36mvisualize_directly\u001b[0;34m(originals, noises, noise_maps, noisy_images, labels, class_names, epoch)\u001b[0m\n\u001b[1;32m    241\u001b[0m noisy_bgr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(noisy_np, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n\u001b[1;32m    242\u001b[0m noisy_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sample_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_noisy_image.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 243\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_bgr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# 4. 保存方差热图\u001b[39;00m\n\u001b[1;32m    246\u001b[0m nv_map \u001b[38;5;241m=\u001b[39m noise_map\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#生成器为resnet18\n",
    "\n",
    "# 读取CIFAR10数据集并加载至内存中\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import warnings\n",
    "from torch.nn.functional import normalize\n",
    "from math import sqrt \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# 检查并下载CIFAR10数据集\n",
    "def download_cifar10():\n",
    "    base_path = \"/gemini/data-3\"\n",
    "    dataset_path = os.path.join(base_path, \"cifar-10-batches-py\")\n",
    "    \n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(\"Downloading CIFAR-10 dataset...\")\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "        \n",
    "        import urllib.request\n",
    "        import tarfile\n",
    "        \n",
    "        url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "        filename = os.path.join(base_path, \"cifar-10-python.tar.gz\")\n",
    "        \n",
    "        # 下载数据集\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        print(\"Download complete!\")\n",
    "        \n",
    "        # 解压文件\n",
    "        with tarfile.open(filename, 'r:gz') as tar:\n",
    "            tar.extractall(path=base_path)\n",
    "        print(f\"Dataset extracted to: {dataset_path}\")\n",
    "    \n",
    "    return dataset_path\n",
    "\n",
    "# 读取文件\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# 提取每一个通道的数据，进行重新排列，最后返回一张32x32的3通道的图片：\n",
    "def GetPhoto(pixel):\n",
    "    assert len(pixel) == 3072\n",
    "    r = pixel[0:1024]; r = np.reshape(r, [32, 32, 1])\n",
    "    g = pixel[1024:2048]; g = np.reshape(g, [32, 32, 1])\n",
    "    b = pixel[2048:3072]; b = np.reshape(b, [32, 32, 1])\n",
    "    photo = np.concatenate([r, g, b], -1)\n",
    "    return photo\n",
    "\n",
    "# 按照给出的关键字提取数据 \n",
    "def getTrainDataByKeyword(keyword, size=(32, 32), normalized=False, filelist=[1,2,3,4,5]):\n",
    "    base_path = download_cifar10()\n",
    "    \n",
    "    # 使用字符串类型处理关键字\n",
    "    if isinstance(keyword, bytes):\n",
    "        keyword = keyword.decode('utf-8')\n",
    "    \n",
    "    keyword_bytes = str.encode(keyword)\n",
    "    \n",
    "    assert keyword_bytes in [b'data', b'labels', b'batch_label', b'filenames']\n",
    "    assert type(filelist) is list and len(filelist) != 0\n",
    "    assert type(normalized) is bool\n",
    "    assert type(size) is tuple\n",
    "\n",
    "    files = []\n",
    "    for i in filelist:\n",
    "        if 1 <= i <= 5 and i not in files:\n",
    "            files.append(i)\n",
    "\n",
    "    if len(files) == 0:\n",
    "        raise ValueError(\"No valid input files!\")\n",
    "\n",
    "    if keyword_bytes == b'data':\n",
    "        data = []\n",
    "        for i in files:\n",
    "            data.append(unpickle(os.path.join(base_path, f\"data_batch_{i}\"))[b'data'])\n",
    "        data = np.concatenate(data, 0)\n",
    "        array = np.ndarray([len(data), size[0], size[1], 3], dtype=np.float32)\n",
    "        for i in range(len(data)):\n",
    "            img = cv2.resize(GetPhoto(data[i]), size)\n",
    "            if normalized:\n",
    "                img = img / 255.0\n",
    "            array[i] = img\n",
    "        return array\n",
    "    \n",
    "    if keyword_bytes == b'labels':\n",
    "        labels = []\n",
    "        for i in files:\n",
    "            labels += unpickle(os.path.join(base_path, f\"data_batch_{i}\"))[b'labels']\n",
    "        return labels\n",
    "    \n",
    "    elif keyword_bytes == b'batch_label':\n",
    "        batch_label = []\n",
    "        for i in files:\n",
    "            batch_label.append(unpickle(os.path.join(base_path, f\"data_batch_{i}\"))[b'batch_label'])\n",
    "        return batch_label\n",
    "    \n",
    "    elif keyword_bytes == b'filenames':\n",
    "        filenames = []\n",
    "        for i in files:\n",
    "            filenames += unpickle(os.path.join(base_path, f\"data_batch_{i}\"))[b'filenames']\n",
    "        return filenames\n",
    "\n",
    "# 提取测试集中的数据\n",
    "def getTestDataByKeyword(keyword, size=(32, 32), normalized=False):\n",
    "    base_path = download_cifar10()\n",
    "    \n",
    "    # 使用字符串类型处理关键字\n",
    "    if isinstance(keyword, bytes):\n",
    "        keyword = keyword.decode('utf-8')\n",
    "    \n",
    "    keyword_bytes = str.encode(keyword)\n",
    "\n",
    "    assert keyword_bytes in [b'data', b'labels', b'batch_label', b'filenames']\n",
    "    assert type(size) is tuple\n",
    "    assert type(normalized) is bool\n",
    "\n",
    "    test_file = os.path.join(base_path, \"test_batch\")\n",
    "    test_data = unpickle(test_file)\n",
    "\n",
    "    if keyword_bytes == b'data':\n",
    "        data = test_data[b'data']\n",
    "        array = np.ndarray([len(data), size[0], size[1], 3], dtype=np.float32)\n",
    "        for i in range(len(data)):\n",
    "            img = cv2.resize(GetPhoto(data[i]), size)\n",
    "            if normalized:\n",
    "                img = img / 255.0\n",
    "            array[i] = img\n",
    "        return array\n",
    "    \n",
    "    elif keyword_bytes == b'labels':\n",
    "        return test_data[b'labels']\n",
    "    \n",
    "    elif keyword_bytes == b'batch_label':\n",
    "        return test_data[b'batch_label']\n",
    "    \n",
    "    elif keyword_bytes == b'filenames':\n",
    "        return test_data[b'filenames']\n",
    "    \n",
    "    else:\n",
    "        raise NameError(f\"Invalid keyword: {keyword}\")\n",
    "\n",
    "# 定义一个数据集类，用于加载CIFAR10数据集\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_directly(originals, noises, noise_maps, noisy_images, labels, class_names, epoch):\n",
    "    \"\"\"\n",
    "    保存可视化结果到文件\n",
    "    每个样本保存: 原始图像、噪声图、噪声图像、方差热图\n",
    "    同时保存四图拼接的对比图\n",
    "    \n",
    "    :param originals: 原始图像列表 (在[0,1]范围)\n",
    "    :param noises: 噪声列表\n",
    "    :param noise_maps: 噪声图列表 (单个通道的方差图)\n",
    "    :param noisy_images: 添加噪声后的图像列表 (在[0,1]范围)\n",
    "    :param labels: 图像标签列表\n",
    "    :param class_names: 类别名称列表\n",
    "    :param epoch: 当前训练轮次\n",
    "    \"\"\"\n",
    "    # 创建主保存目录\n",
    "    main_dir = f\"visualizations/epoch_{epoch}\"\n",
    "    os.makedirs(main_dir, exist_ok=True)\n",
    "    \n",
    "    # 为每个类别创建子目录\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(main_dir, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "    # 处理每个样本\n",
    "    for i, (orig, noise, noise_map, noisy_img, label) in enumerate(zip(\n",
    "        originals, noises, noise_maps, noisy_images, labels)):\n",
    "        \n",
    "        # 获取类别名称\n",
    "        class_idx = label.item()\n",
    "        class_name = class_names[class_idx]\n",
    "        \n",
    "        # 为当前样本创建目录\n",
    "        sample_dir = os.path.join(main_dir, class_name, f\"sample_{i}\")\n",
    "        os.makedirs(sample_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. 保存原始图像\n",
    "        orig_np = orig.permute(1, 2, 0).cpu().numpy() * 255\n",
    "        orig_np = np.clip(orig_np, 0, 255).astype(np.uint8)\n",
    "        orig_bgr = cv2.cvtColor(orig_np, cv2.COLOR_RGB2BGR)\n",
    "        orig_path = os.path.join(sample_dir, f\"{class_name}_original.png\")\n",
    "        cv2.imwrite(orig_path, orig_bgr)\n",
    "        \n",
    "        # 2. 保存噪声图 (三通道彩色)\n",
    "        noise_np = noise.permute(1, 2, 0).cpu().numpy()\n",
    "        max_val = np.max(np.abs(noise_np))\n",
    "        scaled_noise = noise_np / (2 * max_val) + 0.5 if max_val > 0 else 0.5\n",
    "        scaled_noise = np.clip(scaled_noise, 0, 1)\n",
    "        noise_rgb = (scaled_noise * 255).astype(np.uint8)\n",
    "        noise_bgr = cv2.cvtColor(noise_rgb, cv2.COLOR_RGB2BGR)\n",
    "        noise_path = os.path.join(sample_dir, f\"{class_name}_noise.png\")\n",
    "        cv2.imwrite(noise_path, noise_bgr)\n",
    "        \n",
    "        # 3. 保存噪声图像 (添加噪声后的图像)\n",
    "        noisy_np = noisy_img.permute(1, 2, 0).cpu().numpy() * 255\n",
    "        noisy_np = np.clip(noisy_np, 0, 255).astype(np.uint8)\n",
    "        noisy_bgr = cv2.cvtColor(noisy_np, cv2.COLOR_RGB2BGR)\n",
    "        noisy_path = os.path.join(sample_dir, f\"{class_name}_noisy_image.png\")\n",
    "        cv2.imwrite(noisy_path, noisy_bgr)\n",
    "        \n",
    "        # 4. 保存方差热图\n",
    "        nv_map = noise_map.squeeze().cpu().numpy()\n",
    "        nv_map = np.nan_to_num(nv_map)\n",
    "        if np.max(nv_map) - np.min(nv_map) == 0:\n",
    "            nv_map_normalized = np.zeros_like(nv_map)\n",
    "        else:\n",
    "            nv_map_normalized = (nv_map - np.min(nv_map)) / (np.max(nv_map) - np.min(nv_map))\n",
    "        \n",
    "        heatmap = cv2.applyColorMap((nv_map_normalized * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        heatmap_path = os.path.join(sample_dir, f\"{class_name}_variance_heatmap.png\")\n",
    "        cv2.imwrite(heatmap_path, heatmap)\n",
    "        \n",
    "        # 5. 创建并保存四图拼接图\n",
    "        \n",
    "        create_grid_figure(class_name, epoch, sample_dir, \n",
    "                          [orig_bgr, noise_bgr, heatmap, noisy_bgr], \n",
    "                          [\"Original\", \"Generated Noise\", \"Variance Heatmap\", \"π-Noise Image\"])\n",
    "    \n",
    "    print(f\"Visualization saved for epoch {epoch} at: {main_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_grid_figure(class_name, epoch, sample_dir, images, titles):\n",
    "    \"\"\"\n",
    "    创建并保存带标题的四图网格\n",
    "    \n",
    "    :param class_name: 类别名称\n",
    "    :param epoch: 训练轮次\n",
    "    :param sample_dir: 保存目录\n",
    "    :param images: 图像列表 (BGR格式)\n",
    "    :param titles: 标题列表\n",
    "    \"\"\"\n",
    "    # 创建新图\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    fig.suptitle(f\"Epoch {epoch} - {class_name} Visualization\", fontsize=16)\n",
    "    \n",
    "    # 设置每个子图\n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        # 转换BGR为RGB\n",
    "        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(rgb_img)\n",
    "        axs[i].set_title(title, fontsize=12)\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    \n",
    "    # 保存图像\n",
    "    quad_path = os.path.join(sample_dir, f\"{class_name}_grid_{epoch}.png\")\n",
    "    plt.savefig(quad_path, bbox_inches='tight', dpi=120)\n",
    "    plt.close(fig)\n",
    "\n",
    "   \n",
    "\n",
    "# 类别名称 (英文避免中文字体问题)\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# 读取训练集和测试集数据\n",
    "print(\"Loading training data...\")\n",
    "train_data = getTrainDataByKeyword('data', normalized=True, filelist=[1,2,3,4,5])  # 使用全部5个训练批次\n",
    "train_labels = getTrainDataByKeyword('labels', filelist=[1,2,3,4,5])\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_data = getTestDataByKeyword('data', normalized=True)\n",
    "test_labels = getTestDataByKeyword('labels')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# 定义数据预处理转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # 将图像转换为张量并自动缩放到[0,1]\n",
    "])\n",
    "\n",
    "# 创建数据集对象\n",
    "train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform)\n",
    "\n",
    "# 创建数据加载器 (批量大小256，符合论文)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "# 定义基模型\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 根据论文精确实现的VPN生成器\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class ResnetVPNGenerator(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResnetVPNGenerator, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.gamma = 0.01 * (1.0 / num_classes)  # γ = 0.01 × 1/|Y|\n",
    "        \n",
    "        # 使用ResNet18作为特征提取器\n",
    "        self.resnet = models.resnet18(pretrained=False)\n",
    "        # 调整ResNet的第一层卷积以适应CIFAR-10 (32x32图像)\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet.maxpool = nn.Identity()  # 移除maxpool层以适应小尺寸图像\n",
    "        \n",
    "        # 替换最后一层全连接层以输出方差 (3*32*32)\n",
    "        self.resnet.fc = nn.Linear(512, 3 * 32 * 32)\n",
    "        \n",
    "        # 零均值假设 (μ = 0)\n",
    "        self.zero_mean = True\n",
    "\n",
    "    def sample(self, mu, variance, num=1):\n",
    "        # 扩展方差和均值的维度以进行采样\n",
    "        var = variance.expand(num, *variance.size()).transpose(0, 1)\n",
    "        m = mu.expand(num, *mu.size()).transpose(0, 1)\n",
    "        # 生成标准正态分布的随机噪声\n",
    "        epsilon = torch.randn_like(var).to(var.device)\n",
    "        # 重参数化公式：noise = μ + ε * σ\n",
    "        noise = var * epsilon + m\n",
    "        return noise\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 2. 准备标签特征：将标签索引复制为与图像相同维度的向量\n",
    "        y_replicated = y.unsqueeze(1).repeat(1, 3 * 32 * 32).float()\n",
    "        label_vec = self.gamma * y_replicated  # [0~0.01]\n",
    "        label_vec = label_vec.view(batch_size, 3, 32, 32)\n",
    "        \n",
    "        # 3. 组合特征：将图像和标签向量结合\n",
    "        combined = torch.clamp(x + label_vec, 0.0, 1.0)\n",
    "        \n",
    "        # 1. 准备图像特征：直接使用ResNet处理图像\n",
    "        img_features = self.resnet(combined)\n",
    "        \n",
    "        # 4. 通过ResNet生成方差\n",
    "        log_var = self.resnet.fc(img_features)\n",
    "        variance = torch.sigmoid(log_var)\n",
    "        \n",
    "        # 使用截断，限制方差在[C1,C2]范围\n",
    "        variance = torch.clamp(variance, 0.01, 0.1)\n",
    "        variance = (variance-C1)\n",
    "        \n",
    "        # 均值设为0（Zero Mean assumption）\n",
    "        mu = torch.zeros_like(variance)\n",
    "        \n",
    "        # 5. 重参数化采样 (噪声大小m=1)\n",
    "        noise = self.sample(mu, variance)\n",
    "        \n",
    "        # 6. 重塑噪声为图像形状\n",
    "        noise = noise.view(batch_size, 3, 32, 32)\n",
    "        \n",
    "        # 7. 应用噪声到原始图像\n",
    "        noisy_img = x + noise\n",
    "        noisy_img = torch.clamp(noisy_img, 0.0, 1.0)  # 保持[0,1]范围\n",
    "        \n",
    "        # 8. 计算方差热图用于可视化\n",
    "        noise_map = noise.var(dim=1, keepdim=True)  # 在通道维度计算方差\n",
    "        noise_map = torch.clamp(noise_map, min=1e-5)\n",
    "        \n",
    "        return noisy_img, noise, noise_map\n",
    "\n",
    "    \n",
    "\n",
    "# 定义模型\n",
    "base_model = BaseModel()\n",
    "vpn_generator = VPNGenerator(num_classes=10, noise_m=1)\n",
    "\n",
    "# 定义损失函数和优化器 (使用论文指定的学习率0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(base_model.parameters()) + list(vpn_generator.parameters()), \n",
    "                      lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# 学习率调度器 (论文未指定，但StepLR有助于收敛)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "base_model.to(device)\n",
    "vpn_generator.to(device)\n",
    "\n",
    "# 训练轮数40 (论文指定浅层模型)\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "# 根据论文精确实现的VPN损失函数\n",
    "def vpn_loss_function(base_output, vpn_output, gt_labels, noise_cov, criterion, c1=0.01, c2=0.3):\n",
    "    \"\"\"\n",
    "    计算VPN损失函数\n",
    "    \n",
    "    Args:\n",
    "        base_output: 基模型的输出\n",
    "        vpn_output: 加入VPN噪声后的基模型输出\n",
    "        gt_labels: 真实标签\n",
    "        noise_cov: 噪声的协方差矩阵 (方差)\n",
    "        criterion: 基础损失函数 (如CrossEntropyLoss)\n",
    "        c1, c2: 噪声强度约束参数\n",
    "    \n",
    "    Returns:\n",
    "        VPN损失以及基模型损失\n",
    "    \"\"\"\n",
    "    # 基模型损失\n",
    "    base_loss = criterion(base_output, gt_labels)\n",
    "    \n",
    "    # VPN损失 (公式来自论文中的LVPN)\n",
    "    vpn_loss = -torch.mean(torch.log_softmax(vpn_output, dim=1).gather(1, gt_labels.unsqueeze(1)).squeeze(1))\n",
    "    \n",
    "    # 噪声强度约束损失\n",
    "    # 计算每个样本的协方差矩阵范数 (Frobenius范数)\n",
    "    noise_norm = torch.norm(noise_cov.view(noise_cov.size(0), -1), p='fro', dim=1)\n",
    "    # 应用约束 C1 ≤ ∥Σ∥ ≤ C2\n",
    "    constraint_loss = torch.mean(torch.relu(c1 - noise_norm) + torch.relu(noise_norm - c2))\n",
    "    \n",
    "    # 总损失 (结合基模型损失、VPN损失和约束损失)\n",
    "    total_loss = 0.7*base_loss + 0.3*vpn_loss + 0* constraint_loss\n",
    "    \n",
    "    return total_loss, base_loss, vpn_loss \n",
    "\n",
    "\n",
    "# 双重训练模型 (基模型和VPN生成器一起训练)\n",
    "for epoch in range(num_epochs):\n",
    "    base_model.train()\n",
    "    vpn_generator.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # 存储样本用于可视化\n",
    "    sample_originals, sample_noises, sample_noise_maps, sample_noisy_imgs, sample_labels = [], [], [], [], []\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # 生成VPN噪声 (噪声大小m=1)\n",
    "        noisy_data, noise, noise_map = vpn_generator(data, target)\n",
    "\n",
    "\n",
    "                # 保存一些样本用于可视化（每epoch的第一个batch）\n",
    "        if batch_idx == 0 and epoch % 5 == 0:  # 每5个epoch可视化一次\n",
    "            for i in range(5):\n",
    "                # 使用.detach()将张量从计算图中分离\n",
    "                sample_originals.append(data[i].clone().detach())\n",
    "                sample_noises.append(noise[i].clone().detach())\n",
    "                sample_noise_maps.append(noise_map[i].clone().detach())\n",
    "                sample_noisy_imgs.append(noisy_data[i].clone().detach())\n",
    "                sample_labels.append(target[i].clone().detach())\n",
    "        \n",
    "        \n",
    "        # 计算基模型在干净数据和噪声数据上的输出\n",
    "        base_output = base_model(data)\n",
    "        vpn_output = base_model(noisy_data)\n",
    "        \n",
    "        # 计算联合损失\n",
    "        loss, base_loss, vpn_loss = vpn_loss_function(base_output, vpn_output, target, noise, criterion)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计信息\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(vpn_output, 1)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "        total_samples += data.size(0)\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}, Base Loss: {base_loss.item():.4f}, VPN Loss: {vpn_loss.item():.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "        # 可视化噪声（每5个epoch）\n",
    "    if epoch % 5 == 0 and len(sample_originals) > 0:\n",
    "        visualize_directly(\n",
    "            sample_originals,\n",
    "            sample_noises,\n",
    "            sample_noise_maps,\n",
    "            sample_noisy_imgs,\n",
    "            sample_labels,\n",
    "            class_names,\n",
    "            epoch\n",
    "        )\n",
    "    \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Total Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
    "    \n",
    "\n",
    "# 测试模型\n",
    "print(\"\\nTesting model...\")\n",
    "base_model.eval()\n",
    "vpn_generator.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "# 存储测试样本用于可视化\n",
    "test_originals, test_noises, test_noise_maps, test_noisy_imgs, test_labels = [], [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # 生成VPN噪声\n",
    "        noisy_data, noise, noise_map = vpn_generator(data, target)\n",
    "        \n",
    "        # 保存一些样本用于可视化\n",
    "        if batch_idx == 0:\n",
    "            for i in range(5):\n",
    "                # 使用.detach()将张量从计算图中分离\n",
    "                test_originals.append(data[i].clone().detach())\n",
    "                test_noises.append(noise[i].clone().detach())\n",
    "                test_noise_maps.append(noise_map[i].clone().detach())\n",
    "                test_noisy_imgs.append(noisy_data[i].clone().detach())\n",
    "                test_labels.append(target[i].clone().detach())\n",
    "        \n",
    "        # 计算预测结果\n",
    "        output = base_model(noisy_data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "# 最终测试可视化\n",
    "if len(test_originals) > 0:\n",
    "    visualize_directly(\n",
    "        test_originals,\n",
    "        test_noises,\n",
    "        test_noise_maps,\n",
    "        test_noisy_imgs,\n",
    "        test_labels,\n",
    "        class_names,\n",
    "        \"Final\"\n",
    "    )\n",
    "\n",
    "test_loss = test_loss / total\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cf848-9d87-4778-8c92-1777e00d4a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
